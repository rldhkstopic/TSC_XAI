{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LRP:\n",
    "    def __init__(self, model, epsilon=1e-6):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_relevance(self, x, lengths, target=None):\n",
    "        output, hidden_states, attn_weights = self.model(x, lengths, lstm_outputs=True)\n",
    "\n",
    "        if target is None:\n",
    "            target = torch.argmax(output, dim=1)  \n",
    "\n",
    "        relevance = torch.zeros_like(output)\n",
    "        for i in range(output.size(0)):\n",
    "            relevance[i, target[i]] = output[i, target[i]]\n",
    "\n",
    "        relevance = self.compute_relevance(hidden_states, relevance, attn_weights)\n",
    "        return relevance\n",
    "\n",
    "    def compute_relevance(self, hidden_states, relevance, attn_weights):\n",
    "        batch_size, seq_len, hidden_size = hidden_states.size()\n",
    "        relevance_h = torch.zeros_like(hidden_states)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            relevance_t = relevance[i].unsqueeze(0).expand(seq_len, -1) * attn_weights[i].unsqueeze(-1)\n",
    "            relevance_h[i] = torch.sum(hidden_states[i] * relevance_t, dim=-1)\n",
    "\n",
    "        return relevance_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.LSTM import BiLSTM\n",
    "\n",
    "def complex_sep(data):\n",
    "    data = data.replace('i', 'j')  # 'i'를 'j'로 변경하여 복소수 형식에 맞춤\n",
    "    complex_numbers = data.split(',')  # 쉼표로 구분된 복소수 분리\n",
    "    complex_list = []\n",
    "    for num in complex_numbers:\n",
    "        num = complex(num.strip())\n",
    "        complex_list.append(num)\n",
    "    return complex_list\n",
    "\n",
    "def exaplin_set(data):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(data, dtype=torch.float).unsqueeze(0)\n",
    "        lengths = torch.tensor([len(data)], dtype=torch.long)\n",
    "        relevance = lrp.get_relevance(x, lengths)\n",
    "\t\n",
    "\t\n",
    "        \n",
    "dataset = '/data/kiwan/dataset-CWD-1000/'\n",
    "signals = ['Barker', 'Costas', 'Frank', 'LFM', 'P1', 'P2', 'P3', 'P4', 'T1', 'T2', 'T3', 'T4']\n",
    "\n",
    "for signal in signals:\n",
    "    real_parts = []\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    data_dir = os.path.join(dataset, signal)\n",
    "    data_file = os.listdir(data_dir)\n",
    "    for ie, file in enumerate(data_file):\n",
    "        with open(os.path.join(data_dir, file), 'r') as f:\n",
    "            data = f.readlines()\n",
    "            data = [complex_sep(d) for d in data]\n",
    "            data = [item for sublist in data for item in sublist]\n",
    "            \n",
    "            \n",
    "\n",
    "        for c in data:\n",
    "            real_parts.append(c.real)\n",
    "\n",
    "        plt.axvline(x=len(real_parts), color='r', linestyle='--')\n",
    "            \n",
    "        if ie == 5:\n",
    "            break\n",
    "\n",
    "\n",
    "    plt.plot(real_parts, label='Real Part')\n",
    "    # plt.plot(imag_parts, label='Imaginary Part')\n",
    "    plt.title(f'{signal} Signal: Real and Imaginary Parts over Time')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models._config as c\n",
    "\n",
    "from dataset.RadarDataset import RadarSignalDataset\n",
    "\n",
    "train_dataset = RadarSignalDataset(TrainData, c.signalTypes[0:c.typeSize], snr_max=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_set(train_dataset):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "\n",
    "    batch = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=model.collate)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_batch, labels, snr, lengths in batch:\n",
    "            for i in range(len(data_batch)):\n",
    "                data = data_batch[i]\n",
    "                seq_len = lengths[i].item()  \n",
    "                print(seq_len)\n",
    "                \n",
    "                # LRP로 Relevance 스코어 계산\n",
    "                r_scores = lrp.get_relevance(data, seq_len)\n",
    "\n",
    "                real_part = data_batch[i][:, 0].cpu().numpy()  # 실수부\n",
    "                r_scores_real = r_scores[:, 0].cpu().numpy()   # Relevance 실수부\n",
    "\n",
    "                ax = fig.add_subplot(4, 2, i + 1)\n",
    "                ax.plot(real_part, label='Real Part')\n",
    "                ax.plot(r_scores_real, label='Relevance (Real Part)', linestyle='--')\n",
    "                ax.set_title(f'Sample {i+1} (SNR: {snr[i]} dB)')\n",
    "                ax.legend()\n",
    "\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "explain_set(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
