{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Loading Train Data [True]>>\n",
      "Data loading for 'Barker'.....Done!\n",
      "Data loading for 'Costas'.....Done!\n",
      "Data loading for 'Frank'.....Done!\n",
      "Data loading for 'LFM'.....Done!\n",
      "Data loading for 'P1'.....Done!\n",
      "Data loading for 'P2'.....Done!\n",
      "Data loading for 'P3'.....Done!\n",
      "Data loading for 'P4'.....Done!\n",
      "Data loading for 'T1'.....Done!\n",
      "Data loading for 'T2'.....Done!\n",
      "Data loading for 'T3'.....Done!\n",
      "Data loading for 'T4'.....Done!\n"
     ]
    }
   ],
   "source": [
    "from models._config import C\n",
    "from dataset.RadarDataset import RadarSignalDataset  \n",
    "\n",
    "\n",
    "c = C()\n",
    "if __name__ == \"__main__\":\n",
    "    datajson = c.dataload(csv=True, mode='train')\n",
    "    dataset = RadarSignalDataset(datajson, c.signalTypes[0:c.typeSize], snr_max=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: tensor([9, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 150\u001b[0m\n\u001b[1;32m    147\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[1;32m    148\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m--> 150\u001b[0m explain_set(dataset)\n",
      "Cell \u001b[0;32mIn[2], line 132\u001b[0m, in \u001b[0;36mexplain_set\u001b[0;34m(train_dataset)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data_batch, labels_batch, snrs_batch, lengths_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch):\n\u001b[1;32m    131\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGround Truth:\u001b[39m\u001b[39m\"\u001b[39m, labels_batch)\n\u001b[0;32m--> 132\u001b[0m     r_scores \u001b[39m=\u001b[39m lrp\u001b[39m.\u001b[39mrelevance(data_batch, lengths_batch)\n\u001b[1;32m    134\u001b[0m     real_part \u001b[39m=\u001b[39m data_batch[batch_idx][:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# 실수부\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     imag_part \u001b[39m=\u001b[39m data_batch[batch_idx][:, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# 허수부\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mLRP.relevance\u001b[0;34m(self, x, lengths, target)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrelevance\u001b[39m(\u001b[39mself\u001b[39m, x, lengths, target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     output, h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x, lengths, lstm_outputs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m target\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Output shape: torch.Size([batch_size, cls_size])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# Hidden states shape: torch.Size([batch_size, length, hidden_size*2])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Attention weights shape: torch.Size([batch_size, length])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# Context shape: torch.Size([batch_size, hidden_size*2])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/TSC_XAI/models/LSTM.py:55\u001b[0m, in \u001b[0;36mBiLSTM.forward\u001b[0;34m(self, x, lengths, lstm_outputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m lengths \u001b[39m=\u001b[39m lengths\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     52\u001b[0m packed_x \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mpack_padded_sequence(x, lengths, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, enforce_sorted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m packed_out, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(packed_x, (h0, c0))\n\u001b[1;32m     56\u001b[0m out, _ \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mpad_packed_sequence(packed_out, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(seq_len)\u001b[39m.\u001b[39mexpand(batch_size, seq_len)\u001b[39m.\u001b[39mto(device) \u001b[39m<\u001b[39m lengths\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:882\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    879\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n\u001b[1;32m    884\u001b[0m output \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\n\u001b[1;32m    885\u001b[0m hidden \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.LSTM import BiLSTM\n",
    "\n",
    "\n",
    "class LRP:\n",
    "    def __init__(self, model, epsilon=1e-6):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def relevance(self, x, lengths, target=None):\n",
    "        output, h, w = self.model(x, lengths, lstm_outputs=True)\n",
    "        target = torch.argmax(output, dim=1) if target is None else target\n",
    "        # Output shape: torch.Size([batch_size, cls_size])\n",
    "        # Hidden states shape: torch.Size([batch_size, length, hidden_size*2])\n",
    "        # Attention weights shape: torch.Size([batch_size, length])\n",
    "        # Context shape: torch.Size([batch_size, hidden_size*2])\n",
    "        \n",
    "        r = torch.zeros_like(output)\n",
    "        for i in range(output.size(0)):\n",
    "            r[i, target[i]] = output[i, target[i]] # Target class에 대한 relevance만 생존\n",
    "        \n",
    "        r_c = self.bpp_fc(h, r)\n",
    "        r_h = self.bpp_att(r_c, h, w)\n",
    "        r_x = self.bpp_lstm(r_h, h, lengths)\n",
    "        \n",
    "        return r_x\n",
    "    \n",
    "    def lstm_gates(self, x_t, h_prev, W_ih, W_hh, b_ih, b_hh, cl_prev):\n",
    "        gates = torch.matmul(W_ih, x_t) + torch.matmul(W_hh, h_prev) + b_ih + b_hh\n",
    "        i_t, f_t, o_t, g_t = torch.chunk(gates, 4, dim=0)\n",
    "        \n",
    "        i_t = torch.sigmoid(i_t)\n",
    "        f_t = torch.sigmoid(f_t)\n",
    "        o_t = torch.sigmoid(o_t)\n",
    "        cl_t = f_t * cl_prev + i_t * torch.tanh(g_t)\n",
    "        \n",
    "        return (f_t, i_t, o_t, cl_t)\n",
    "    \n",
    "    \n",
    "    def bpp_bilstm(self, rel_h, h, x, lengths):\n",
    "        batch_size, seq_len, hidden_size = h.size()\n",
    "        hidden_size = hidden_size // 2\n",
    "        \n",
    "        rel_x_fw = torch.zeros(batch_size, seq_len, 2)\n",
    "        rel_cl_fw_t1 = torch.zeros(batch_size, hidden_size)\n",
    "        W_ih = self.model.lstm.weight_ih_l0\n",
    "        W_hh = self.model.lstm.weight_hh_l0\n",
    "        b_ih = self.model.lstm.bias_ih_l0\n",
    "        b_hh = self.model.lstm.bias_hh_l0\n",
    "        \n",
    "        rel_x_bw = torch.zeros(batch_size, seq_len, 2)\n",
    "        rel_cl_bw_t1 = torch.zeros(batch_size, hidden_size)\n",
    "        W_ih_bw = self.model.lstm.weight_ih_l0_reverse\n",
    "        W_hh_bw = self.model.lstm.weight_hh_l0_reverse\n",
    "        b_ih_bw = self.model.lstm.bias_ih_l0_reverse\n",
    "        b_hh_bw = self.model.lstm.bias_hh_l0_reverse\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            h_prev_fw = torch.zeros(hidden_size)\n",
    "            cl_prev_fw = torch.zeros(hidden_size)\n",
    "            for t in reversed(range(seq_len)):\n",
    "                if t < lengths[i]:\n",
    "                    x_t = x[i, t]\n",
    "                    h_fw_t = h[i, t, :hidden_size]\n",
    "                    rel_h_fw_t = rel_h[i, t, :hidden_size]\n",
    "                    gates_fw = self.lstm_gates(x_t, h_prev_fw, W_ih, W_hh, b_ih, b_hh, cl_prev_fw)\n",
    "                    rel_x_fw[i, t], rel_cl_fw_t1 = self.bpp_lstm_cell(h_fw_t, rel_h_fw_t, rel_cl_fw_t1, gates_fw, W_ih)\n",
    "                    \n",
    "                    h_prev_fw = h_fw_t\n",
    "                    cl_prev_fw = gates_fw[-1]\n",
    "            \n",
    "            h_prev_bw = torch.zeros(hidden_size)\n",
    "            cl_prev_bw = torch.zeros(hidden_size)\n",
    "            for t in range(seq_len):\n",
    "                if t < lengths[i]:\n",
    "                    x_t = x[i, t]\n",
    "                    h_bw_t = h[i, t, hidden_size:]\n",
    "                    rel_h_bw_t = rel_h[i, t, hidden_size:]\n",
    "                    gates_bw = self.lstm_gates(x_t, h_prev_bw, W_ih_bw, W_hh_bw, b_ih_bw, b_hh_bw, cl_prev_bw)\n",
    "                    rel_x_bw[i, t], rel_cl_bw_t1 = self.bpp_lstm_cell(h_bw_t, rel_h_bw_t, rel_cl_bw_t1, gates_bw, W_ih_bw)\n",
    "             \n",
    "                    h_prev_bw = h_bw_t\n",
    "                    cl_prev_bw = gates_bw[-1]\n",
    "                    \n",
    "        rel_x = rel_x_fw + rel_x_bw\n",
    "        return rel_x\n",
    "        \n",
    "    def bpp_lstm_cell(self, rel_h_t, rel_cl_t1, gates, W_ih):\n",
    "        f_t, i_t, o_t, cl_t = gates\n",
    "        \n",
    "        rel_cl_t = rel_cl_t1 + rel_h_t * o_t * (1-torch.tanh(cl_t)**2)\n",
    "        rel_cl_t1 = rel_cl_t * f_t\n",
    "        \n",
    "        rel_x_t = torch.matmul(W_ih.T, rel_cl_t * i_t)\n",
    "        return rel_x_t, rel_cl_t1\n",
    "        \n",
    "    def bpp_att(self, r_c, h, w):\n",
    "        rel_h = torch.zeros_like(h)\n",
    "        for i in range(h.size(0)):\n",
    "            rel_h_t = r_c[i].unsqueeze(0) * w[i].unsqueeze(-1)\n",
    "            rel_h[i] = rel_h_t\n",
    "\n",
    "        return rel_h\n",
    "    \n",
    "    def bpp_fc(self, c, r):\n",
    "        fc_W = self.model.fc.weight\n",
    "        rel_c = torch.zeros_like(c)\n",
    "        for i in range(r.size(0)):\n",
    "            for j in range(r.size(1)):\n",
    "                rel_c[i] += (c[i]*fc_W[j]) * r[i, j] / (fc_W[j].abs().sum() + self.epsilon)\n",
    "        return rel_c\n",
    "        \n",
    "    \n",
    "    \n",
    "def explain_set(train_dataset):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "\n",
    "    batch = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=model.collate)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data_batch, labels_batch, snrs_batch, lengths_batch) in enumerate(batch):\n",
    "            r_scores = lrp.relevance(data_batch, lengths_batch)\n",
    "\n",
    "            real_part = data_batch[batch_idx][:, 0].cpu().numpy()  # 실수부\n",
    "            imag_part = data_batch[batch_idx][:, 1].cpu().numpy()  # 허수부\n",
    "            r_scores_real = r_scores[:, 0].cpu().numpy()   # Relevance 실수부\n",
    "\n",
    "            # 그래프 그리기\n",
    "            ax = fig.add_subplot(4, 2, batch_idx + 1)\n",
    "            ax.plot(real_part, label='Real Part')\n",
    "            ax.plot(r_scores_real, label='Relevance (Real Part)', linestyle='--')\n",
    "            ax.set_title(f'Sample {batch_idx+1} (SNR: {snrs_batch[batch_idx]} dB)')\n",
    "            ax.legend()\n",
    "\n",
    "            break  # 첫 번째 배치만 시각화\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "explain_set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.LSTM import BiLSTM\n",
    "\n",
    "def complex_sep(data):\n",
    "    data = data.replace('i', 'j')  # 'i'를 'j'로 변경하여 복소수 형식에 맞춤\n",
    "    complex_numbers = data.split(',')  # 쉼표로 구분된 복소수 분리\n",
    "    complex_list = []\n",
    "    for num in complex_numbers:\n",
    "        num = complex(num.strip())\n",
    "        complex_list.append(num)\n",
    "    return complex_list\n",
    "\n",
    "def exaplin_set(data):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(data, dtype=torch.float).unsqueeze(0)\n",
    "        lengths = torch.tensor([len(data)], dtype=torch.long)\n",
    "        relevance = lrp.get_relevance(x, lengths)\n",
    "\t\n",
    "\t\n",
    "        \n",
    "dataset = '/data/kiwan/dataset-CWD-1000/'\n",
    "signals = ['Barker', 'Costas', 'Frank', 'LFM', 'P1', 'P2', 'P3', 'P4', 'T1', 'T2', 'T3', 'T4']\n",
    "\n",
    "for signal in signals:\n",
    "    real_parts = []\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    data_dir = os.path.join(dataset, signal)\n",
    "    data_file = os.listdir(data_dir)\n",
    "    for ie, file in enumerate(data_file):\n",
    "        with open(os.path.join(data_dir, file), 'r') as f:\n",
    "            data = f.readlines()\n",
    "            data = [complex_sep(d) for d in data]\n",
    "            data = [item for sublist in data for item in sublist]\n",
    "            \n",
    "            \n",
    "\n",
    "        for c in data:\n",
    "            real_parts.append(c.real)\n",
    "\n",
    "        plt.axvline(x=len(real_parts), color='r', linestyle='--')\n",
    "            \n",
    "        if ie == 5:\n",
    "            break\n",
    "\n",
    "\n",
    "    plt.plot(real_parts, label='Real Part')\n",
    "    # plt.plot(imag_parts, label='Imaginary Part')\n",
    "    plt.title(f'{signal} Signal: Real and Imaginary Parts over Time')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_set(train_dataset):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "\n",
    "    batch = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=model.collate)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_batch, labels, snr, lengths in batch:\n",
    "            for i in range(len(data_batch)):\n",
    "                data = data_batch[i]\n",
    "                seq_len = lengths[i].item()  \n",
    "                print(seq_len)\n",
    "                \n",
    "                # LRP로 Relevance 스코어 계산\n",
    "                r_scores = lrp.get_relevance(data, seq_len)\n",
    "\n",
    "                real_part = data_batch[i][:, 0].cpu().numpy()  # 실수부\n",
    "                r_scores_real = r_scores[:, 0].cpu().numpy()   # Relevance 실수부\n",
    "\n",
    "                ax = fig.add_subplot(4, 2, i + 1)\n",
    "                ax.plot(real_part, label='Real Part')\n",
    "                ax.plot(r_scores_real, label='Relevance (Real Part)', linestyle='--')\n",
    "                ax.set_title(f'Sample {i+1} (SNR: {snr[i]} dB)')\n",
    "                ax.legend()\n",
    "\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "explain_set(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
