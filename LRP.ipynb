{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Loading Train Data [True]>>\n",
      "Data loading for 'Barker'.....Done!\n",
      "Data loading for 'Costas'.....Done!\n",
      "Data loading for 'Frank'.....Done!\n",
      "Data loading for 'LFM'.....Done!\n",
      "Data loading for 'P1'.....Done!\n",
      "Data loading for 'P2'.....Done!\n",
      "Data loading for 'P3'.....Done!\n",
      "Data loading for 'P4'.....Done!\n",
      "Data loading for 'T1'.....Done!\n",
      "Data loading for 'T2'.....Done!\n",
      "Data loading for 'T3'.....Done!\n",
      "Data loading for 'T4'.....Done!\n"
     ]
    }
   ],
   "source": [
    "from models._config import C\n",
    "from dataset.RadarDataset import RadarSignalDataset  \n",
    "\n",
    "\n",
    "c = C()\n",
    "if __name__ == \"__main__\":\n",
    "    datajson = c.dataload(csv=True, mode='train')\n",
    "    dataset = RadarSignalDataset(datajson, c.signalTypes[0:c.typeSize], snr_max=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from matplotlib import pyplot as plt\n",
    "    \n",
    "# Temporal Attention Layer (Zero-padding에 대한 가중치 조정 포함)\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)  # \n",
    "        self.v = nn.Parameter(torch.rand(hidden_size)) # \n",
    "        \n",
    "    def forward(self, hidden_states, mask=None):\n",
    "        \"\"\"\n",
    "        hidden_states: [batch_size, seq_len, hidden_size * 2]\n",
    "        mask: [batch_size, seq_len] - zero-padding mask\n",
    "        \"\"\"\n",
    "        attn_weights = torch.tanh(self.attn(hidden_states))  # [batch_size, seq_len, hidden_size]\n",
    "        attn_weights = attn_weights.matmul(self.v)           # [batch_size, seq_len]\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)        # [batch_size, seq_len]에서 softmax로 중요도 결정\n",
    "        \n",
    "        # 가중치를 반영하여 각 타임 스텝의 hidden state를 곱해줌\n",
    "        context = torch.sum(hidden_states * attn_weights.unsqueeze(-1), dim=1)  # [batch_size, hidden_size * 2]\n",
    "        return context, attn_weights\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        \n",
    "        self.attention = SelfAttention(hidden_size)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, lengths, lstm_outputs=False):\n",
    "        device = self.device\n",
    "        x = x.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        print(\"f\", x.device, lengths.device)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size, device=device)\n",
    "        packed_x = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        \n",
    "        packed_out, (hn, cn) = self.lstm(packed_x, (h0, c0))\n",
    "        out, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        mask = torch.arange(seq_len).expand(batch_size, seq_len).to(device) < lengths.unsqueeze(1).to(device)\n",
    "        \n",
    "        context, attn_weights = self.attention(out, mask) \n",
    "        \n",
    "        out_last = self.dropout(context) \n",
    "        out_fc = self.fc(out_last) \n",
    "                \n",
    "        if lstm_outputs:\n",
    "            return out_fc, out, attn_weights\n",
    "        else:\n",
    "            return out_fc\n",
    "\n",
    "\n",
    "    @staticmethod        \n",
    "    def collate(batch):\n",
    "        data, labels, snrs, lengths = zip(*batch)\n",
    "        \n",
    "        data_pad = rnn_utils.pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in data], batch_first=True)\n",
    "        \n",
    "        labels = torch.tensor([c.label_mapping[label] for label in labels], dtype=torch.long)\n",
    "        snrs = torch.tensor(snrs, dtype=torch.int64)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.int64)  # 시퀀스 길이를 함께 전달\n",
    "\n",
    "        return data_pad, labels, snrs, lengths\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barker\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from models.LSTM import BiLSTM\n",
    "\n",
    "\n",
    "class LRP:\n",
    "    def __init__(self, model, device, epsilon=1e-6):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "    \n",
    "    def relevance(self, x, lengths, target=None):\n",
    "        x = x.to(self.device)\n",
    "        lengths = lengths.to(self.device)\n",
    "        output, h, a = self.model(x, lengths, lstm_outputs=True)\n",
    "        target = torch.argmax(output, dim=1) if target is None else target\n",
    "        # Output shape: torch.Size([B, cls])\n",
    "        # Hidden states shape: torch.Size([B, T, H*2])\n",
    "        # Attention weights shape: torch.Size([B, T])\n",
    "        # Context shape: torch.Size([B, H*2])\n",
    "        \n",
    "        r = torch.zeros_like(output)\n",
    "        for i in range(output.size(0)):\n",
    "            r[i, target[i]] = output[i, target[i]] # Target class에 대한 relevance만 생존\n",
    "        \n",
    "        r_c = self.bpp_fc(h, r)\n",
    "        r_h = self.bpp_att(r_c, h, a)\n",
    "        r_x = self.bpp_bilstm(r_h, h, x, lengths)\n",
    "        \n",
    "        # ground truth\n",
    "        gt_label = torch.argmax(output, dim=1)\n",
    "        return r_x, gt_label\n",
    "    \n",
    "    def lstm_gates(self, x_t, h_prev, W_ih, W_hh, b_ih, b_hh, cl_prev):\n",
    "        x_t = x_t.to(self.device)\n",
    "        h_prev = h_prev.to(self.device)\n",
    "        cl_prev = cl_prev.to(self.device)\n",
    "        \n",
    "        gates = torch.matmul(W_ih, x_t) + torch.matmul(W_hh, h_prev) + b_ih + b_hh\n",
    "        i_t, f_t, o_t, g_t = torch.chunk(gates, 4, dim=0)\n",
    "        \n",
    "        i_t = torch.sigmoid(i_t)\n",
    "        f_t = torch.sigmoid(f_t)\n",
    "        o_t = torch.sigmoid(o_t)\n",
    "        cl_t = f_t * cl_prev + i_t * torch.tanh(g_t)\n",
    "        \n",
    "        return (f_t, i_t, o_t, cl_t)\n",
    "        \n",
    "    def bpp_bilstm(self, rel_h, h, x, lengths):\n",
    "        B, T, H = h.size()\n",
    "        H = H // 2\n",
    "        D = x.size(-1)\n",
    "        \n",
    "        rel_x_fw = torch.zeros(B, T, D)                     # [B, T, D]\n",
    "        rel_cl_fw_t1 = torch.zeros(B, H)                    # [B, H]\n",
    "        W_ih = self.model.lstm.weight_ih_l0                             # [4*h, input_size]\n",
    "        W_hh = self.model.lstm.weight_hh_l0                             # [4*h, hidden_size]\n",
    "        b_ih = self.model.lstm.bias_ih_l0\n",
    "        b_hh = self.model.lstm.bias_hh_l0\n",
    "        \n",
    "        rel_x_bw = torch.zeros(B, T, 2)\n",
    "        rel_cl_bw_t1 = torch.zeros(B, H)\n",
    "        W_ih_bw = self.model.lstm.weight_ih_l0_reverse\n",
    "        W_hh_bw = self.model.lstm.weight_hh_l0_reverse\n",
    "        b_ih_bw = self.model.lstm.bias_ih_l0_reverse\n",
    "        b_hh_bw = self.model.lstm.bias_hh_l0_reverse\n",
    "        \n",
    "        # relevance는 cell state와 gate 값들을 통해 전파됨\n",
    "        # rel_h_t : [B, T, sigma]\n",
    "        # rel_x_fw[i, t] : [d] / rel_cl_fw_t1[i] : [h]\n",
    "        for i in range(B):                                    # B\n",
    "            h_prev_fw = torch.zeros(H)\n",
    "            cl_prev_fw = torch.zeros(H)\n",
    "            for t in reversed(range(T)):                      # T\n",
    "                if t < lengths[i]:\n",
    "                    x_t = x[i, t]                             # [H]\n",
    "                    rel_h_fw_t = rel_h[i, t, :H]              # [H]\n",
    "                    \n",
    "                    f_t, i_t, o_t, cl_t = self.lstm_gates(x_t, h_prev_fw, W_ih, W_hh, b_ih, b_hh, cl_prev_fw) # [H]\n",
    "                    rel_x_fw[i, t], rel_cl_fw_t1[i] = self.bpp_lstm_cell(rel_h_fw_t, rel_cl_fw_t1[i], \n",
    "                                                                            f_t, o_t, cl_t, W_ih)              \n",
    "                    cl_prev_fw = cl_t\n",
    "            \n",
    "            h_prev_bw = torch.zeros(H)\n",
    "            cl_prev_bw = torch.zeros(H)\n",
    "            for t in range(T):\n",
    "                if t < lengths[i]:\n",
    "                    x_t = x[i, t]\n",
    "                    rel_h_bw_t = rel_h[i, t, H:]\n",
    "                    bf_t, bi_t, bo_t, bcl_t = self.lstm_gates(x_t, h_prev_bw, W_ih_bw, W_hh_bw, b_ih_bw, b_hh_bw, cl_prev_bw)\n",
    "                    rel_x_bw[i, t], rel_cl_bw_t1[i] = self.bpp_lstm_cell(rel_h_bw_t, rel_cl_bw_t1[i], \n",
    "                                                                            bf_t, bo_t, bcl_t, W_ih_bw)\n",
    "                    cl_prev_bw = bcl_t\n",
    "                    \n",
    "        rel_x = rel_x_fw + rel_x_bw\n",
    "        return rel_x\n",
    "        \n",
    "    def bpp_lstm_cell(self, rel_h_t, rel_cl_t1, f_t, o_t, cl_t, W_ih):\n",
    "        rel_cl_t = rel_cl_t1.to(self.device) + rel_h_t * o_t * (1 - torch.tanh(cl_t) ** 2)  # 전체 흐름 고려\n",
    "    \n",
    "        # 현재 시점에서 forget gate를 통해 이전 시점으로 relevance 전파\n",
    "        rel_cl_t1 = rel_cl_t * f_t\n",
    "        \n",
    "        # Input gate를 통해 입력으로 relevance 전파 (i_t 반영)\n",
    "        _, _, W_ih_o, W_ih_cl = torch.chunk(W_ih, 4, dim=0)  # input gate 가중치 추출\n",
    "        \n",
    "        # Output gate를 통한 relevance 전파\n",
    "        rel_x_o = torch.matmul(W_ih_o.T, rel_cl_t * o_t)  # output gate 사용\n",
    "        # Cell state를 통한 relevance 전파\n",
    "        rel_x_cl = torch.matmul(W_ih_cl.T, rel_cl_t * torch.tanh(cl_t))  # cell state 사용\n",
    "        \n",
    "        # input gate를 통해 relevance 전파 (i_t 반영)\n",
    "        rel_x_t = rel_x_o + rel_x_cl  # 최종 relevance 계산\n",
    "        \n",
    "        return rel_x_t, rel_cl_t1\n",
    "        \n",
    "    def bpp_att(self, r_c, h, w):\n",
    "        rel_h = torch.zeros_like(h)\n",
    "        for i in range(h.size(0)):\n",
    "            rel_h_t = r_c[i].unsqueeze(0) * w[i].unsqueeze(-1)\n",
    "            rel_h[i] = rel_h_t\n",
    "\n",
    "        return rel_h\n",
    "    \n",
    "    def bpp_fc(self, c, r):\n",
    "        fc_W = self.model.fc.weight\n",
    "        rel_c = torch.zeros_like(c)\n",
    "        for i in range(r.size(0)):\n",
    "            for j in range(r.size(1)):\n",
    "                rel_c[i] += (c[i]*fc_W[j]) * r[i, j] / (fc_W[j].abs().sum() + self.epsilon)\n",
    "        return rel_c\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    norm = (data - min_val) / (max_val - min_val + 1e-6)\n",
    "    # norm[norm < 0] = 0\n",
    "    return norm\n",
    "\n",
    "def fft_transform(data_real, data_imag):\n",
    "    complex_signal = data_real + 1j * data_imag     # 복소수 신호로 변환\n",
    "    fft_data = np.fft.fft(complex_signal)           # FFT 적용\n",
    "    fft_amplitude = np.abs(fft_data)                # 주파수 스펙트럼의 크기\n",
    "    return fft_amplitude[:len(fft_amplitude) // 2] \n",
    "\n",
    "\n",
    "def explain_set(config, train_dataset):\n",
    "    device = config.device\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "\n",
    "    state_dict = {}\n",
    "    for k, v in torch.load('./ckpts/result_loss.pt').items():\n",
    "        nk = k.replace('module.', '')\n",
    "        state_dict[nk] = v\n",
    "        \n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()   \n",
    "   \n",
    "    lrp = LRP(model, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_size = 5\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        snr_batch = [(data_batch, labels_batch, snrs_batch, lengths_batch) \n",
    "                     for data_batch, labels_batch, snrs_batch, lengths_batch in train_dataset if snrs_batch == 0 and labels_batch == 'Costas']\n",
    "        batch = DataLoader(snr_batch, batch_size=batch_size, shuffle=False, collate_fn=model.collate)\n",
    "\n",
    "        for batch_idx, (data_batch, labels_batch, snrs_batch, lengths_batch) in enumerate(batch):\n",
    "            r_scores, gt_label = lrp.relevance(data_batch, lengths_batch, target=labels_batch)\n",
    "            seq_len = lengths_batch[batch_idx].item()  # 유효한 시퀀스 길이\n",
    "            \n",
    "            data_real = data_batch[batch_idx, :seq_len, 0].cpu().numpy()  # 실수부\n",
    "            data_imag = data_batch[batch_idx, :seq_len, 1].cpu().numpy()  # 허수부\n",
    "            data_fft = fft_transform(data_real, data_imag)\n",
    "            \n",
    "            rel_real = r_scores[batch_idx, :seq_len, 0].cpu().numpy()   # Relevance 실수부\n",
    "            rel_imag = r_scores[batch_idx, :seq_len, 1].cpu().numpy()   # Relevance 허수부\n",
    "            rel_fft = fft_transform(rel_real, rel_imag)\n",
    "            \n",
    "            data = data_real + data_imag\n",
    "            rel = rel_real + rel_imag  \n",
    "            \n",
    "            rel = rel[:len(data)]\n",
    "            rel_norm = normalize(rel)\n",
    "            rel_fft = rel_fft[:len(data_fft)]\n",
    "            rel_fft_norm = normalize(rel_fft)            \n",
    "\n",
    "            ax1 = fig.add_subplot(batch_size, 2, 2*batch_idx+1)\n",
    "            ax2 = fig.add_subplot(batch_size, 2, 2*batch_idx+2) \n",
    "            \n",
    "            rel_heatmap = np.expand_dims(rel_norm, axis=0)\n",
    "            rel_fft_heatmap = np.expand_dims(rel_fft_norm, axis=0)\n",
    "            \n",
    "            ax1.plot(data_fft, color='black', label='FFT Magnitude', linewidth=0.5)\n",
    "            ax2.plot(data, color='black', label='Signal', linewidth=0.5)\n",
    "            \n",
    "            ax1.imshow(rel_fft_heatmap, cmap='bwr', aspect='auto', interpolation='nearest',\n",
    "                    extent=[0, seq_len // 2, ax1.get_ylim()[0], ax1.get_ylim()[1]], zorder=0, vmin=-1, vmax=1)\n",
    "\n",
    "            ax2.imshow(rel_heatmap, cmap='bwr', aspect='auto', interpolation='nearest',\n",
    "                    extent=[0, seq_len, ax2.get_ylim()[0], ax2.get_ylim()[1]], zorder=0)\n",
    "            \n",
    "            ax1.set_title(f'GT : {gt_label[batch_idx]}label: {labels_batch[batch_idx]}, SNR: {snrs_batch[batch_idx]} dB')\n",
    "            ax2.set_title(f'GT : {gt_label[batch_idx]}label: {labels_batch[batch_idx]}, SNR: {snrs_batch[batch_idx]} dB')\n",
    "            \n",
    "            if batch_idx >= batch_size - 1: \n",
    "                break  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from models._config import C\n",
    "c = C()\n",
    "explain_set(c, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models.LSTM import BiLSTM\n",
    "\n",
    "def complex_sep(data):\n",
    "    data = data.replace('i', 'j')  # 'i'를 'j'로 변경하여 복소수 형식에 맞춤\n",
    "    complex_numbers = data.split(',')  # 쉼표로 구분된 복소수 분리\n",
    "    complex_list = []\n",
    "    for num in complex_numbers:\n",
    "        num = complex(num.strip())\n",
    "        complex_list.append(num)\n",
    "    return complex_list\n",
    "\n",
    "def exaplin_set(data):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(data, dtype=torch.float).unsqueeze(0)\n",
    "        lengths = torch.tensor([len(data)], dtype=torch.long)\n",
    "        relevance = lrp.get_relevance(x, lengths)\n",
    "\t\n",
    "\t\n",
    "        \n",
    "dataset = '/data/kiwan/dataset-CWD-1000/'\n",
    "signals = ['Barker', 'Costas', 'Frank', 'LFM', 'P1', 'P2', 'P3', 'P4', 'T1', 'T2', 'T3', 'T4']\n",
    "\n",
    "for signal in signals:\n",
    "    real_parts = []\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    data_dir = os.path.join(dataset, signal)\n",
    "    data_file = os.listdir(data_dir)\n",
    "    for ie, file in enumerate(data_file):\n",
    "        with open(os.path.join(data_dir, file), 'r') as f:\n",
    "            data = f.readlines()\n",
    "            data = [complex_sep(d) for d in data]\n",
    "            data = [item for sublist in data for item in sublist]\n",
    "            \n",
    "            \n",
    "\n",
    "        for c in data:\n",
    "            real_parts.append(c.real)\n",
    "\n",
    "        plt.axvline(x=len(real_parts), color='r', linestyle='--')\n",
    "            \n",
    "        if ie == 5:\n",
    "            break\n",
    "\n",
    "\n",
    "    plt.plot(real_parts, label='Real Part')\n",
    "    # plt.plot(imag_parts, label='Imaginary Part')\n",
    "    plt.title(f'{signal} Signal: Real and Imaginary Parts over Time')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_set(train_dataset):\n",
    "    model = BiLSTM(input_size=2, hidden_size=128, num_layers=2, num_classes=12)\n",
    "    model.load_state_dict(torch.load('/home/kiwan/TSC_XAI/ckpts/ 0dB/LSTM_ 0dB_0.0073.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    lrp = LRP(model)\n",
    "\n",
    "    batch = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=model.collate)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_batch, labels, snr, lengths in batch:\n",
    "            for i in range(len(data_batch)):\n",
    "                data = data_batch[i]\n",
    "                seq_len = lengths[i].item()  \n",
    "                print(seq_len)\n",
    "                \n",
    "                # LRP로 Relevance 스코어 계산\n",
    "                r_scores = lrp.get_relevance(data, seq_len)\n",
    "\n",
    "                real_part = data_batch[i][:, 0].cpu().numpy()  # 실수부\n",
    "                r_scores_real = r_scores[:, 0].cpu().numpy()   # Relevance 실수부\n",
    "\n",
    "                ax = fig.add_subplot(4, 2, i + 1)\n",
    "                ax.plot(real_part, label='Real Part')\n",
    "                ax.plot(r_scores_real, label='Relevance (Real Part)', linestyle='--')\n",
    "                ax.set_title(f'Sample {i+1} (SNR: {snr[i]} dB)')\n",
    "                ax.legend()\n",
    "\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "explain_set(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
