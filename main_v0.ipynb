{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models._config as c\n",
    "from models.LSTM import BiLSTM\n",
    "from models.Attention import Transformer\n",
    "from explainer import LRP\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Training parameters')\n",
    "parser.add_argument('-m', '--mode', type=str, default='train', help='Mode of operation (train/eval)')\n",
    "\n",
    "parser.add_argument('-smin','--snr_min', type=int, default=0, help='Minimum SNR value')\n",
    "parser.add_argument('-smax','--snr_max', type=int, default=16, help='Maximum SNR value')\n",
    "parser.add_argument('--split_size', type=float, default=0.8, help='Train/Test split size')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training')\n",
    "parser.add_argument('--num_epochs', type=int, default=500, help='Number of epochs for training')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='Learning rate for optimizer')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5, help='Weight decay for optimizer')\n",
    "parser.add_argument('--input_size', type=int, default=2, help='Input size for the model')\n",
    "parser.add_argument('--hidden_size', type=int, default=128, help='Hidden size for the model')\n",
    "parser.add_argument('--num_layers', type=int, default=2, help='Number of layers in the model')\n",
    "parser.add_argument('--num_classes', type=int, default=c.typeSize, help='Number of output classes')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "params = {\n",
    "    'snr_min': args.snr_min,\n",
    "    'snr_max': args.snr_max,\n",
    "    'split_size': args.split_size,\n",
    "    'batch_size': args.batch_size,\n",
    "    'num_epochs': args.num_epochs,\n",
    "    'learning_rate': args.learning_rate,\n",
    "    'weight_decay': args.weight_decay,\n",
    "    'input_size': args.input_size,\n",
    "    'hidden_size': args.hidden_size,\n",
    "    'num_layers': args.num_layers,\n",
    "    'num_classes': args.num_classes\n",
    "}\n",
    "\n",
    "def train_eachset(dataset, mtype='LSTM'):\n",
    "    print(f\"Size of train dataset: {len(dataset)}\")\n",
    "    for snr in range(params['snr_min'], params['snr_max']+1, 2):\n",
    "        print(f\"\\nTraining model for SNR: {snr}...\")\n",
    "        ckpt = os.path.join(\"./ckpts/\", snr_str:=f\"SNR-{snr}dB\" if snr != 0 else \" 0dB\")\n",
    "        os.makedirs(ckpt, exist_ok=True)\n",
    "        \n",
    "        model = BiLSTM(params['input_size'], params['hidden_size'], params['num_layers'], params['num_classes'])\n",
    "        model.to(c.device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # criterion = LabelSmoothingLoss(classes=params['num_classes'], smoothing=0.1).to(c.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], \n",
    "                                                    weight_decay=params['weight_decay'])\n",
    "        \n",
    "        snr_dataset = [(data, label, data_snr, length) for data, label, data_snr, length in dataset if data_snr == snr]\n",
    "        snr_loader = DataLoader(snr_dataset, batch_size=params['batch_size'], shuffle=True, collate_fn=model.collate)\n",
    "            \n",
    "        best_state, best_loss = model.train_model(snr_loader, criterion, optimizer, params['num_epochs'], c.device, snr_str, ckpt)\n",
    "\n",
    "        save_point = f'{ckpt}/{mtype}_{snr_str}_{best_loss:.4f}.pt'\n",
    "        \n",
    "        torch.save(best_state, save_point)\n",
    "        print(f\"Model checkpoint saved at {save_point}\")\n",
    "\n",
    "def train_set(dataset):\n",
    "    print(f\"Size of train dataset: {len(dataset)}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = BiLSTM(params['input_size'], params['hidden_size'], params['num_layers'], params['num_classes'])\n",
    "    \n",
    "    if torch.cuda.device_count()>1:\n",
    "        print(\"use device parallelly : \", torch.cuda.device_count(),\"devices\")\n",
    "        model = nn.DataParallel(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    model.to(c.device)\n",
    "    \n",
    "    \n",
    "    snr_loader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True, collate_fn=model.collate)\n",
    "    best_state, best_loss = model.module.train_model(snr_loader, criterion, optimizer, params['num_epochs'], c.device)\n",
    "\n",
    "\n",
    "    torch.save(best_state, f'./ckpts/result_loss_{best_loss:.4f}.pt')\n",
    "    print(\"Train is done.\")\n",
    "        \n",
    "def eval_set(dataset, mtype='LSTM'):\n",
    "    print(f\"Size of test dataset: {len(dataset)}\")\n",
    "    for snr in range(params['snr_min'], params['snr_max']+1, 2):\n",
    "        ckpt = os.path.join(\"./ckpts/\", snr_str:=f\"SNR-{snr}dB\" if snr != 0 else \" 0dB\")\n",
    "        ckpts = [f for f in os.listdir(ckpt) if f.endswith(\".pt\") and f.startswith(\"LSTM\")]\n",
    "        \n",
    "        model = BiLSTM(params['input_size'], params['hidden_size'], params['num_layers'], params['num_classes']).to(c.device)\n",
    "        model.load_state_dict(torch.load(f\"ckpts/result_loss.pt\"))\n",
    "        model.eval()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        snr_dataset = [(data, label, data_snr, length) for data, label, data_snr, length in dataset if data_snr == snr]\n",
    "        snr_loader = DataLoader(snr_dataset, batch_size=128, shuffle=True, collate_fn=model.collate)\n",
    "        \n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in snr_loader:\n",
    "                data, labels, length = batch[0].to(c.device), batch[1].to(c.device), batch[3]\n",
    "                outputs = model(data, length)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "        acc = correct / total * 100\n",
    "        avg_loss = total_loss / len(snr_loader)\n",
    "        \n",
    "        print(f\"SNR -{snr}dB | Accuracy: {acc:.2f}% | Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Loading Train Data [True]>>\n",
      "Data loading for 'Barker'.....Done!\n",
      "Data loading for 'Costas'.....Done!\n",
      "Data loading for 'Frank'.....Done!\n",
      "Data loading for 'LFM'.....Done!\n",
      "Data loading for 'P1'.....Done!\n",
      "Data loading for 'P2'.....Done!\n",
      "Data loading for 'P3'.....Done!\n",
      "Data loading for 'P4'.....Done!\n",
      "Data loading for 'T1'.....Done!\n",
      "Data loading for 'T2'.....Done!\n",
      "Data loading for 'T3'.....Done!\n",
      "Data loading for 'T4'.....Done!\n"
     ]
    }
   ],
   "source": [
    "from dataset.RadarDataset import RadarSignalDataset  \n",
    "\n",
    "from models._config import C\n",
    "c = C()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datajson = c.dataload(csv=True, mode='train')\n",
    "    dataset = RadarSignalDataset(datajson, c.signalTypes[0:c.typeSize], snr_max=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dataset: 108000\n",
      "SNR -0dB | Accuracy: 97.96% | Average Loss: 0.0958\n",
      "SNR -2dB | Accuracy: 96.91% | Average Loss: 0.1434\n",
      "SNR -4dB | Accuracy: 95.30% | Average Loss: 0.2261\n",
      "SNR -6dB | Accuracy: 91.93% | Average Loss: 0.4116\n",
      "SNR -8dB | Accuracy: 87.91% | Average Loss: 0.6351\n",
      "SNR -10dB | Accuracy: 83.05% | Average Loss: 0.9147\n",
      "SNR -12dB | Accuracy: 74.74% | Average Loss: 1.3739\n",
      "SNR -14dB | Accuracy: 62.91% | Average Loss: 2.1408\n",
      "SNR -16dB | Accuracy: 48.99% | Average Loss: 3.2212\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def eval_set(dataset):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Size of test dataset: {len(dataset)}\")\n",
    "    for snr in range(params['snr_min'], params['snr_max']+1, 2):\n",
    "        model = BiLSTM(params['input_size'], params['hidden_size'], params['num_layers'], params['num_classes']).to('cuda')\n",
    "          \n",
    "        state_dict = torch.load(f\"ckpts/result_loss.pt\")\n",
    "\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace('module.', '')  # 'module.' 접두어 제거\n",
    "            new_state_dict[new_key] = v\n",
    "        \n",
    "        model.load_state_dict(new_state_dict)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        snr_dataset = [(data, label, data_snr, length) for data, label, data_snr, length in dataset if data_snr == snr]\n",
    "        snr_loader = DataLoader(snr_dataset, batch_size=128, shuffle=True, collate_fn=model.collate)\n",
    "        \n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in snr_loader:\n",
    "                data, labels, length = batch[0].to(device), batch[1].to(device), batch[3]\n",
    "                outputs = model(data, length)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "        acc = correct / total * 100\n",
    "        avg_loss = total_loss / len(snr_loader)\n",
    "        \n",
    "        print(f\"SNR -{snr}dB | Accuracy: {acc:.2f}% | Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "eval_set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import models._config as c\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "    \n",
    "# Temporal Attention Layer (Zero-padding에 대한 가중치 조정 포함)\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)  # BiLSTM이므로 hidden_size * 2\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size)) \n",
    "        \n",
    "    def forward(self, hidden_states, mask=None):\n",
    "        \"\"\"\n",
    "        hidden_states: [batch_size, seq_len, hidden_size * 2]\n",
    "        mask: [batch_size, seq_len] - zero-padding mask\n",
    "        \"\"\"\n",
    "        attn_weights = torch.tanh(self.attn(hidden_states))  # [batch_size, seq_len, hidden_size]\n",
    "        attn_weights = attn_weights.matmul(self.v)           # [batch_size, seq_len]\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.to(attn_weights.device)\n",
    "            attn_weights = attn_weights.masked_fill(mask == 0, -1e9)  # Zero-padding에 대한 large negative\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)  # [batch_size, seq_len]에서 softmax로 중요도 결정\n",
    "        \n",
    "        # 가중치를 반영하여 각 타임 스텝의 hidden state를 곱해줌\n",
    "        context = torch.sum(hidden_states * attn_weights.unsqueeze(-1), dim=1)  # [batch_size, hidden_size * 2]\n",
    "        return context, attn_weights\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Bidirectional LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        self.attention = TemporalAttention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # Bidirectional이므로 hidden_size * 2\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, lengths, lstm_outputs=False):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Initial hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # PackedSequence로 변환하여 RNN/LSTM에서 패딩 무시\n",
    "        packed_x = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (hn, cn) = self.lstm(packed_x, (h0, c0))  # LSTM 통과\n",
    "        \n",
    "        # 다시 패딩된 시퀀스로 변환\n",
    "        out, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        # Zero-padding Mask 생성\n",
    "        mask = torch.arange(seq_len).expand(batch_size, seq_len) < lengths.unsqueeze(1)\n",
    "        \n",
    "        # Attention with Zero-padding Mask 적용\n",
    "        context, attn_weights = self.attention(out, mask)  # Self-Attention 통과\n",
    "        \n",
    "        out_last = self.dropout(context)  # Dropout\n",
    "        out_fc = self.fc(out_last)  # Fully connected layer\n",
    "                \n",
    "        if lstm_outputs:\n",
    "            return out_fc, out, attn_weights\n",
    "        else:\n",
    "            return out_fc\n",
    "\n",
    "\n",
    "    def train_model(self, train_loader, criterion, optimizer, num_epochs, device):\n",
    "        vis = visdom.Visdom()\n",
    "        assert vis.check_connection(), \"Visdom 서버를 실행 필수 : python -m visdom.server\"\n",
    "\n",
    "        losses = []  \n",
    "        vis_window = vis.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1,)).cpu(),\n",
    "            opts=dict(xlabel='Epoch', ylabel='Loss', title=f'Training Loss', legend=['Loss'])\n",
    "        )\n",
    "        \n",
    "        best_loss = float('inf')  # Best loss 초기화\n",
    "        best_state = None\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()  \n",
    "            running_loss = 0.0  \n",
    "            \n",
    "            progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "            \n",
    "            for batch_idx, (data_batch, labels_batch, _, lengths_batch) in progress_bar:\n",
    "                data_batch = data_batch.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "                lengths_batch = lengths_batch.cpu()  # 시퀀스 길이를 CPU로 이동\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = self(data_batch, lengths_batch)  # self()는 forward()를 호출함\n",
    "                \n",
    "                # Loss 계산\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # 현재 배치 번호와 평균 손실을 tqdm에 표시\n",
    "                progress_bar.set_postfix({\n",
    "                    'Batch': f\"{batch_idx + 1}/{len(train_loader)}\",\n",
    "                    'Loss': f\"{loss.item():.4f}\"\n",
    "                })\n",
    "\n",
    "                loss.detach()\n",
    "\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            losses.append(avg_loss)\n",
    "\n",
    "            vis.line(\n",
    "                X=torch.tensor([epoch + 1]).cpu(),\n",
    "                Y=torch.tensor([avg_loss]).cpu(),\n",
    "                win=vis_window,\n",
    "                update='append'\n",
    "            )\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "            \n",
    "            # Best loss 갱신\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                best_state = self.state_dict()\n",
    "\n",
    "            if best_loss < 0.01:\n",
    "                break\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return best_state, best_loss\n",
    "\n",
    "    @staticmethod        \n",
    "    def collate(batch):\n",
    "        data, labels, snrs, lengths = zip(*batch)\n",
    "        data_pad = rnn_utils.pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in data], batch_first=True)\n",
    "        \n",
    "        labels = torch.tensor([c.label_mapping[label] for label in labels], dtype=torch.long)\n",
    "        snrs = torch.tensor(snrs, dtype=torch.float32)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.long)  # 시퀀스 길이를 함께 전달\n",
    "\n",
    "        return data_pad, labels, snrs, lengths\n",
    "\n",
    "\n",
    "# def train_set(dataset):\n",
    "\n",
    "print(f\"Size of train dataset: {len(train_dataset)}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = BiLSTM(params['input_size'], params['hidden_size'], params['num_layers'], params['num_classes'])\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs with DataParallel.\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to('cuda')\n",
    "else:\n",
    "    model.to(c.device)\n",
    "    \n",
    "optimizer = optim.Adam(model.module.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "\n",
    "snr_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=model.module.collate, num_workers=8)\n",
    "# best_state, best_loss = model.module.train_model(snr_loader, criterion, optimizer, params['num_epochs'], c.device)\n",
    "\n",
    "\n",
    "# torch.save(best_state, f'./ckpts/result_loss_{best_loss:.4f}.pt')\n",
    "# print(\"Train is done.\")\n",
    "    \n",
    "# train_set(train_dataset) # 8374MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state, best_loss = model.module.train_model(snr_loader, criterion, optimizer, params['num_epochs'], c.device)\n",
    "\n",
    "\n",
    "torch.save(best_state, f'./ckpts/result_loss_{best_loss:.4f}.pt')\n",
    "print(\"Train is done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#for j in range(data.size(0)):\n",
    "#   relevance = lrp.get_relevance(data[j]) # [seq_len, input_size]\n",
    "\n",
    "class LRP:\n",
    "    def __init__(self, model, epsilon=1e-5):\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward(self, x, lstm_outputs):\n",
    "        return self.model(x, lstm_outputs)\n",
    "    \n",
    "    def get_relevance(self, x, target=None):        \n",
    "        x.requires_grad = True\n",
    "        output, hiddens = self.forward(x, lstm_outputs=True) # [32, 4] | [32, 1495, 256]\n",
    "        # output은 모델의 예측 결과, hid_outputs는 LSTM의 각 시간 스텝의 hidden state를 포함\n",
    "        # output : [batch_size, num_classes], hiddens : [batch_size, seq_len, hidden_size]\n",
    "        target = torch.argmax(output, dim=1) if target is None else torch.tensor(target).to(x.device)\n",
    "\n",
    "        # 정답 클래스에 대한 기여도 초기화\n",
    "        relevance = torch.zeros_like(output)\n",
    "        for i in range(output.size(0)):\n",
    "            relevance[i, target[i]] = output[i, target[i]]\n",
    "        \n",
    "        relevance = relevance.unsqueeze(1).expand(-1, hiddens.size(1), -1) # [batch_size, seq_len, num_classes]\n",
    "        \n",
    "        \n",
    "        for module in reversed(list(self.model.modules())):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                relevance = self.linear_lrp(module, hiddens, relevance)\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                relevance = self.bilstm_lrp(module, hiddens, relevance)\n",
    "            elif isinstance(module, nn.ReLU) or isinstance(module, nn.Tanh):\n",
    "                relevance = self.activation_lrp(module, hiddens, relevance)\n",
    "                \n",
    "        return relevance\n",
    "\n",
    "\n",
    "    # hiddens : torch.Size([32, 1495, 256]) : [batch_size, seq_len, hidden_size] | relevance : torch.Size([32, 4])\n",
    "    def linear_lrp(self, layer, hiddens, relevance): \n",
    "        print(hiddens.size())\n",
    "        batch_size, seq_len, _ = hiddens.size()\n",
    "        \n",
    "        weight = layer.weight  # [num_classes, hidden_size]\n",
    "        bias = layer.bias      # [num_classes]\n",
    "        total_relevance = torch.zeros_like(hiddens)  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            hiddens_i = hiddens[i]                           # [seq_len, hidden_size]\n",
    "            relevance_i = relevance[i]                       # [num_classes]\n",
    "            total_relevance_i = torch.zeros_like(hiddens_i)  # [seq_len, hidden_size]\n",
    "\n",
    "            for t in range(seq_len):\n",
    "                h_t = hiddens_i[t, :]                              \n",
    "                z_t = F.linear(h_t, weight, bias) + self.epsilon   \n",
    "                s_t = relevance_i / z_t                            \n",
    "                c_t = torch.matmul(s_t, weight)                    \n",
    "\n",
    "                total_relevance_i[t, :] = h_t * c_t  # [hidden_size]\n",
    "\n",
    "            total_relevance[i] = total_relevance_i\n",
    "\n",
    "        print(total_relevance.size())  # total_relevance: [batch_size, seq_len, hidden_size]\n",
    "        return total_relevance\n",
    "    \n",
    "    def bilstm_lrp(self, layer, hiddens, relevance):\n",
    "        batch_size, seq_len, hidden_size2 = hiddens.size()\n",
    "        hidden_size = hidden_size2 // 2                     # only one-direction hidden size\n",
    "        \n",
    "        h_fw, h_bw = hiddens[:, :, :hidden_size], hiddens[:, :, hidden_size:]\n",
    "        rel_fw, rel_bw = torch.zeros_like(h_fw), torch.zeros_like(h_bw)\n",
    "        \n",
    "        for t in reversed(range(seq_len)):\n",
    "            h_t_fw = h_fw[:, t, :]  # [batch_size, hidden_size]\n",
    " \n",
    "            z_t_fw = F.linear(h_t_fw, layer.weight_ih_l0, layer.bias_ih_l0) + self.epsilon\n",
    "                    \n",
    "            s_t_fw = relevance / (z_t_fw + self.epsilon)\n",
    "            c_t_fw = s_t_fw @ layer.weight_ih_l0[:hidden_size, :].t() \n",
    "            rel_fw[:, t, :] = h_t_fw * c_t_fw\n",
    "            \n",
    "            h_t_bw = h_bw[:, t, :]  # [batch_size, hidden_size]\n",
    "            z_t_bw = F.linear(h_t_bw, layer.weight_ih_l0_reverse, layer.bias_ih_l0_reverse) + self.epsilon\n",
    "            s_t_bw = relevance / (z_t_bw + self.epsilon)\n",
    "            c_t_bw = s_t_bw @ layer.weight_ih_l0[hidden_size:, :].t()\n",
    "            rel_bw[:, t, :] = h_t_bw * c_t_bw\n",
    "            \n",
    "        total_relevance = rel_fw + rel_bw\n",
    "        print(f\"total relevance: {total_relevance.size()}\")\n",
    "        return total_relevance\n",
    " \n",
    "    def compute_lstm_relevance(self, layer, x, relevance, direction='forward'):\n",
    "        \"\"\"\n",
    "        LSTM의 각 시간 스텝에 대해 relevance 계산.\n",
    "        - layer: nn.LSTM 레이어\n",
    "        - x: 입력 텐서\n",
    "        - relevance: 기여도 텐서\n",
    "        - direction: 'forward' or 'backward' (방향 선택)\n",
    "        \"\"\"\n",
    "        # 정방향 또는 역방향 LSTM의 각 시간 스텝에 대해 relevance를 계산\n",
    "        seq_len = x.size(1)\n",
    "        \n",
    "        # 방향에 따라 시퀀스를 정방향 또는 역방향으로 순회하며 기여도 계산\n",
    "        if direction == 'forward':\n",
    "            time_steps = range(seq_len)\n",
    "        elif direction == 'backward':\n",
    "            time_steps = reversed(range(seq_len))\n",
    "        \n",
    "        # 시퀀스를 순회하면서 각 시간 스텝에 대한 기여도 계산\n",
    "        for t in time_steps:\n",
    "            h_t = layer(x[:, t, :])[0]  # 현재 시간 스텝의 LSTM 출력\n",
    "            z = h_t + self.epsilon  # 작은 epsilon 추가\n",
    "            s = relevance[:, t, :] / z  # relevance 계산\n",
    "            relevance[:, t, :] = x[:, t, :] * s\n",
    "        \n",
    "        return relevance\n",
    "    \n",
    "    def activation_lrp(self, layer, x, relevance):\n",
    "        \"\"\"\n",
    "        활성화 함수의 LRP 계산 (ReLU, Tanh 등).\n",
    "        활성화 함수에서는 LRP를 사용하여 기여도 역전파를 수행.\n",
    "        \"\"\"\n",
    "        # 활성화 함수의 입력 x에 대해 기여도를 직접 역전파\n",
    "        return relevance * (x > 0).float()  # 활성화된 뉴런만 기여도를 전달\n",
    "\n",
    "\n",
    "explain_set(explain_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from explainer import LRP\n",
    "\n",
    "def explain_mode(dataset):\n",
    "    print(f\"Size of test dataset: {len(dataset)}\")\n",
    "    for snr in range(params['snr_min'], params['snr_max']+1, 2):\n",
    "        ckpt = os.path.join(\"./ckpts/\", snr_str:=f\"-{snr}dB\" if snr != 0 else \"0dB\")\n",
    "        ckpts = [f for f in os.listdir(ckpt) if f.endswith(\".pt\")]\n",
    "\n",
    "        model = BiLSTM(params['input_size'], params['hidden_size'], \n",
    "                    params['num_layers'], params['num_classes']).to(c.device)\n",
    "        model.load_state_dict(torch.load(f\"{ckpt}/{ckpts[0]}\"))\n",
    "        model.eval()\n",
    "        \n",
    "        explainer = LRP(model)\n",
    "        dataset_batch = DataLoader(dataset, batch_size=params['batch_size'], shuffle=False, collate_fn=model.collate)\n",
    "        for data, labels, _ in dataset_batch:\n",
    "            data = data.to(c.device)\n",
    "            relevances = explainer.get_relevance(data)\n",
    "            num_classes = relevances.shape[3]\n",
    "            \n",
    "            for i, d, l in zip(range(len(data)), data, labels):\n",
    "                fig, axs = plt.subplots(1, num_classes, figsize=(20, 5))\n",
    "                for class_idx in range(num_classes):\n",
    "                    relevance_class = relevances[i, :, :, class_idx].sum(axis=1) # sum over input channels\n",
    "                    real, imag = data[i, :, 0].cpu().numpy(), data[i, :, 1].cpu().numpy()\n",
    "                    \n",
    "                    axs[class_idx].plot(real, color='gray', label='Real')\n",
    "                    \n",
    "                    relv_pos = np.where(relevance_class > 0, relevance_class, np.nan)\n",
    "                    relv_neg = np.where(relevance_class < 0, relevance_class, np.nan)\n",
    "                    \n",
    "                    ax2 = axs[class_idx].twinx()\n",
    "                    ax2.plot(relv_pos, color='red', label='Positive Relevance')\n",
    "                    ax2.plot(relv_neg, color='blue', label='Negative Relevance')\n",
    "                    # ax2.set_ylim(-0.5, 0.5)\n",
    "                    ax2.set_yticks([])\n",
    "        \n",
    "                plt.subtitle(f'LRP values for {l} sample {i} at SNR -{snr}dB')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                break\n",
    "            break\n",
    "        break            \n",
    "        \n",
    "explain_mode(explain_dataset)\n",
    "\n",
    "# 데이터셋을 불러오는 과정에서 패딩은 해당 배치에서 가장 길이가 긴 값을 기준으로 이루어지기 때문에 data의 일부가 0으로 되어있을 수 있음\n",
    "# \n",
    "# shap 값은 해당 데이터의 실제 값과 비교하여 어떤 부분이 중요한지를 나타내는 값이기 때문에 0으로 패딩된 부분은 중요하지 않음\n",
    "# 따라서 shap 값을 보기 위해서는 해당 데이터의 실제 값만을 보는 것이 좋음\n",
    "# 이를 반영해 코드는 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_mode(dataset):\n",
    "    print(f\"Size of test dataset: {len(dataset)}\")\n",
    "    for snr in range(params['snr_min'], params['snr_max']+1, 2):\n",
    "        ckpt = os.path.join(\"./ckpts/\", snr_str:=f\"-{snr}dB\" if snr != 0 else \"0dB\")\n",
    "        ckpts = [f for f in os.listdir(ckpt) if f.endswith(\".pt\")]\n",
    "\n",
    "        LSTMmodel = BiLSTM(params['input_size'], params['hidden_size'], \n",
    "                    params['num_layers'], params['num_classes']).to(c.device)\n",
    "        LSTMmodel.load_state_dict(torch.load(f\"{ckpt}/{ckpts[0]}\"))\n",
    "        \n",
    "        \n",
    "        dataset_batch = DataLoader(dataset, batch_size=params['batch_size'], shuffle=False, collate_fn=LSTMmodel.collate)\n",
    "        for data, labels, _ in dataset_batch:\n",
    "            data = data.to(c.device)\n",
    "            \n",
    "            for i, d, l in zip(range(len(data)), data, labels):                \n",
    "                fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "                for class_idx in range(2): \n",
    "                    # shap_class = shap_values[i, :, :, class_idx].sum(axis=1)\n",
    "                    \n",
    "                    real_data = data[i, :, 0].cpu().numpy()\n",
    "                    imag_data = data[i, :, 1].cpu().numpy()\n",
    "                    \n",
    "                    axs[class_idx].plot(real_data, color='blue') # plot(x, y)\n",
    "                    axs[class_idx+1].plot(imag_data, color='orange')\n",
    "                    # shap_pos = np.where(shap_class >= 0, shap_class, np.nan)\n",
    "                    # shap_neg = np.where(shap_class < 0, shap_class, np.nan)\n",
    "                    \n",
    "                    # ax2 = axs[class_idx].twinx()\n",
    "                    # ax2.plot(shap_pos, label='Positive SHAP', color='orange', linestyle='--', alpha=0.7)\n",
    "                    # ax2.plot(shap_neg, label='Negative SHAP', color='blue', linestyle='--', alpha=0.7)\n",
    " \n",
    "                    # ax2.set_ylim(-0.06, 0.053)\n",
    "                    # ax2.set_yticks([])\n",
    "                    # ax2.legend(loc='upper right')\n",
    "                    \n",
    "                    # axs[class_idx].set_title(f'Class {class_idx}')\n",
    "                    # axs[class_idx].set_xlabel('Time')\n",
    "                    # axs[class_idx].set_ylabel('SHAP value')\n",
    "                    \n",
    "                    # axs[class_idx].grid(True)\n",
    "                    \n",
    "                plt.suptitle(f'SHAP values for {l} Sample {i} at SNR {snr_str}')\n",
    "                plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "                plt.show()\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "        \n",
    "explain_mode(explain_dataset)\n",
    "\n",
    "# 데이터셋을 불러오는 과정에서 패딩은 해당 배치에서 가장 길이가 긴 값을 기준으로 이루어지기 때문에 data의 일부가 0으로 되어있을 수 있음\n",
    "# \n",
    "# shap 값은 해당 데이터의 실제 값과 비교하여 어떤 부분이 중요한지를 나타내는 값이기 때문에 0으로 패딩된 부분은 중요하지 않음\n",
    "# 따라서 shap 값을 보기 위해서는 해당 데이터의 실제 값만을 보는 것이 좋음\n",
    "# 이를 반영해 코드는 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from TripletConvolution import TCN, trainTCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "signalTypes = ['Barker', 'Costas', 'Frank', 'LFM', 'P1', 'P2', 'P3', 'P4', 'T1', 'T2', 'T3', 'T4']\n",
    "\n",
    "RawType = \"/data/kiwan/dataset-CWD-50/\"\n",
    "TransformedTypes = {'DWT' : \"/data/kiwan/Unknown_radar_detection/Adaptive_wavelet_transform/dataset-SPWVD-denoised-Adaptive_DWT\",\n",
    "                    'CWD' : \"/data/kiwan/Unknown_radar_detection/Adaptive_wavelet_transform/240523_CWD-v1/\",\n",
    "                    'SAFI' : \"/data/kiwan/Unknown_radar_detection/Adaptive_wavelet_transform/240523_SAFI-v1/\",}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'dataset/CWD_signals.json'\n",
    "\n",
    "with open(json_file, 'r') as f:\n",
    "    SignalData = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [signal_type]>[snr_value]>[step]>[timepoint][real, imag]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class RadarSignalDataset(Dataset):\n",
    "    def __init__(self, signals_data, signal_types, snr_max=17):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_mapping = {signal: idx for idx, signal in enumerate(signalTypes)}\n",
    "\n",
    "        for signal_type in signal_types:\n",
    "            print(f\"Data loading for '{signal_type}'\", end='')\n",
    "            for snr_idx, snr in enumerate(range(0, snr_max, 2)): \n",
    "                print(\".\", end='') if snr_idx % 2 == 0 else None\n",
    "                ssnr = str(snr)\n",
    "                if ssnr in signals_data[signal_type]: \n",
    "                    signal_snr_data = signals_data[signal_type][ssnr]\n",
    "                    for signal in signal_snr_data:\n",
    "                        complex_signal = [self.convIQ(x) for x in signal]\n",
    "                        self.data.append(complex_signal)\n",
    "                        self.labels.append(signal_type)\n",
    "            print(\"Done!\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def convIQ(datastring):\n",
    "        comp = complex(datastring.replace('i', 'j'))\n",
    "        return comp.real, comp.imag\n",
    "    \n",
    "    staticmethod\n",
    "    def collate(self, batch):\n",
    "        data, labels = zip(*batch)\n",
    "        padding = rnn_utils.pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in data], batch_first=True)\n",
    "        labels = [self.label_mapping[label] for label in labels]\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return padding, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeSize = 4\n",
    "dataset = RadarSignalDataset(SignalData, signalTypes[0:typeSize], snr_max=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dataset.collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial hidden state와 cell state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))     # LSTM 출력: (배치 크기, 시퀀스 길이, hidden state 크기)\n",
    "        out = self.fc(out[:, -1, :])        # 마지막 타임스텝만 사용하여 출력 계산\n",
    "        return out\n",
    "\n",
    "input_size = 2          # (Real, Imag)\n",
    "hidden_size = 128       # LSTM hidden state size\n",
    "num_layers = 2          \n",
    "num_classes = len(signalTypes[:typeSize])  # Expected Output size\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40 \n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    rl = 0.0\n",
    "    \n",
    "    for data_batch, labels_batch in train_loader:\n",
    "        data_batch = data_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch)\n",
    "\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        rl += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {rl/len(train_loader):.4f}')\n",
    "torch.save(model.state_dict(), f'./lstm_l{rl/len(train_loader):.4f}.pt')\n",
    "\n",
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data_batch, labels_batch in test_loader:\n",
    "        data_batch = data_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        outputs = model(data_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels_batch.size(0)\n",
    "        correct += (predicted == labels_batch).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 0\n",
    "targetSNR = 0\n",
    "\n",
    "vDataset = [(d,l,s) for d, l, s, _ in Dataset if s == targetSNR and signalTypes[l] in signal_groups[f'v{version}']]\n",
    "\n",
    "plot = {}\n",
    "for data, label, _ in vDataset:\n",
    "    signalType = signalTypes[label]\n",
    "    if signalType not in plot:\n",
    "        plot[signalType] = data\n",
    "\n",
    "fig, axs = plt.subplots(1, len(plot))\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "for i, (signal_type, image) in enumerate(plot.items()):\n",
    "    axs[i].imshow(image.squeeze(), cmap='gray')\n",
    "    axs[i].set_title(signal_type)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn = TCN(input_channel=1).cuda() \n",
    "optimizer = optim.Adam(tcn.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "maxSNR = 2\n",
    "unique_labels = np.unique([l for _, l, _ in vDataset])\n",
    "\n",
    "for snr in range(0, maxSNR, 2):\n",
    "    snrDataset = [(d,l,s) for d, l, s in vDataset if s == snr]\n",
    "    trainTCN(tcn, optim=optimizer, dataset=snrDataset, data_type='DWT', snr=snr, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
